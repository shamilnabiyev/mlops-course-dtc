{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42a2a44",
   "metadata": {},
   "source": [
    "# MLOps Zoomcamp - Homework #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987649be",
   "metadata": {},
   "source": [
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75466f2d",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47003cb8",
   "metadata": {},
   "source": [
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Download the data for January and February 2021.\n",
    "\n",
    "Note that you need \"For-Hire Vehicle Trip Records\", not \"High Volume For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Read the data for January. How many records are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5952943",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06120f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f379ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 22004\n",
      "-rw-r--r-- 1 user 197121 11886281 May 18 21:37 fhv_tripdata_2021-01.parquet\n",
      "-rw-r--r-- 1 user 197121 10645466 May 18 21:37 fhv_tripdata_2021-02.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0e89dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 218 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00009 2021-01-01 00:27:00 2021-01-01 00:44:00           NaN   \n",
       "1               B00009 2021-01-01 00:50:00 2021-01-01 01:07:00           NaN   \n",
       "2               B00013 2021-01-01 00:01:00 2021-01-01 01:51:00           NaN   \n",
       "3               B00037 2021-01-01 00:13:09 2021-01-01 00:21:26           NaN   \n",
       "4               B00037 2021-01-01 00:38:31 2021-01-01 00:53:44           NaN   \n",
       "\n",
       "   DOlocationID SR_Flag Affiliated_base_number  \n",
       "0           NaN    None                 B00009  \n",
       "1           NaN    None                 B00009  \n",
       "2           NaN    None                 B00013  \n",
       "3          72.0    None                 B00037  \n",
       "4          61.0    None                 B00037  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "df = pd.read_parquet('../data/fhv_tripdata_2021-01.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e5dda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 1154112\n"
     ]
    }
   ],
   "source": [
    "len_df = len(df)\n",
    "print(\"Number of records:\", len_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce6079",
   "metadata": {},
   "source": [
    "## Q2. Computing duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ada43",
   "metadata": {},
   "source": [
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the average trip duration in January?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34dcce",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63528cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_duration_feature(dataset):\n",
    "    \"\"\"Create a new feature called duration\"\"\"\n",
    "    dataset['duration'] = dataset.dropOff_datetime - dataset.pickup_datetime\n",
    "    dataset.duration = dataset.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59938203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average trip duration in January was 19.17 minutes\n"
     ]
    }
   ],
   "source": [
    "df = create_duration_feature(df)\n",
    "avg_duration = round(df.duration.mean(), 2)\n",
    "\n",
    "print('Average trip duration in January was', avg_duration, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafed271",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2513ce3",
   "metadata": {},
   "source": [
    "Check the distribution of the duration variable. There are some outliers.\n",
    "\n",
    "Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "How many records did you drop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa18ec",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ecc814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of dropped rows: 44286\n"
     ]
    }
   ],
   "source": [
    "def filter_dataset(dataset):\n",
    "    return dataset[(dataset.duration >= 1) & (dataset.duration <= 60)]\n",
    "\n",
    "df = filter_dataset(df)\n",
    "\n",
    "print(\"The number of dropped rows:\", (len_df - len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b751fcd",
   "metadata": {},
   "source": [
    "## Q3. Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99325e5f",
   "metadata": {},
   "source": [
    "The features we'll use for our model are the pickup and dropoff location IDs.\n",
    "\n",
    "But they have a lot of missing values there. Let's replace them with \"-1\".\n",
    "\n",
    "What's the fractions of missing values for the pickup location ID? I.e. fraction of \"-1\"s after you filled the NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07155110",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee1ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_values(dataset):\n",
    "    \"\"\"Replace missing values by -1\"\"\"\n",
    "    dataset['PUlocationID'] = dataset['PUlocationID'].fillna(-1)\n",
    "    dataset['DOlocationID'] = dataset['DOlocationID'].fillna(-1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4c3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of missing values in the PUlocationID column is 0.84\n"
     ]
    }
   ],
   "source": [
    "df = replace_missing_values(df)\n",
    "\n",
    "missing_values_fraction = round(df['PUlocationID'].value_counts()[-1] / len(df), 2)\n",
    "\n",
    "print('Fraction of missing values in the PUlocationID column is', missing_values_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b68e8",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ecd2e",
   "metadata": {},
   "source": [
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer\n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix? (The number of columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493a6bf",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714c83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionaries(dataset):\n",
    "    \"\"\"Extract features (X) and target variable (y)\"\"\"\n",
    "    # Convert the selected columns to categories\n",
    "    categorical = ['PUlocationID', 'DOlocationID']\n",
    "    dataset[categorical] = dataset[categorical].astype(str)\n",
    "\n",
    "    # Create a list of dictionaries\n",
    "    df_dicts = dataset[categorical].to_dict(orient='records')\n",
    "    return df_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eb0c22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix has 525 columns\n"
     ]
    }
   ],
   "source": [
    "df_dicts = get_dictionaries(df)\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(df_dicts)\n",
    "\n",
    "# Create a target vector for model training\n",
    "y_train = df['duration'].values\n",
    "\n",
    "print(f'The matrix has {X_train.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093196e1",
   "metadata": {},
   "source": [
    "## Q5. Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf97d5e",
   "metadata": {},
   "source": [
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "* Train a plain linear regression model with default parameters\n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7bb189",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0a64c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(estimator, X, y):\n",
    "    model = estimator()\n",
    "    print(f'Training a {model.__class__.__name__} model using default hyperparameters...')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def eval_model(model, X, y, data_info='train'):\n",
    "    print(f'Evaluating the {model.__class__.__name__} model on the {data_info} dataset ...')\n",
    "    \n",
    "    # Predict the values using the training data\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "    return round(rmse, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f472bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LinearRegression model using default hyperparameters...\n",
      "Evaluating the LinearRegression model on the train dataset ...\n",
      "RMSE on the training data: 10.53\n"
     ]
    }
   ],
   "source": [
    "lr_model = train_model(LinearRegression, X_train, y_train)\n",
    "\n",
    "rmse = eval_model(lr_model, X_train, y_train, 'train')\n",
    "print(f'RMSE on the training data: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7401c204",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae60f7c",
   "metadata": {},
   "source": [
    "### Prepare the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44fae06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation matrix has 525 columns\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Load the validation dataset\n",
    "df = pd.read_parquet('../data/fhv_tripdata_2021-02.parquet')\n",
    "\n",
    "# Feature engineering: create an new column\n",
    "df = create_duration_feature(df)\n",
    "\n",
    "# Filter out unused values\n",
    "df = filter_dataset(df)\n",
    "\n",
    "# Replace all NaN values by -1\n",
    "df = replace_missing_values(df)\n",
    "\n",
    "# Create a list of dictionaries\n",
    "df_dicts = get_dictionaries(df)\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "X_val = dv.transform(df_dicts)\n",
    "\n",
    "# Create a target vector for model training\n",
    "y_val = df['duration'].values\n",
    "\n",
    "print(f'The validation matrix has {X_val.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d40a35",
   "metadata": {},
   "source": [
    "### Evaluate the model on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "460f5d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the LinearRegression model on the validation dataset ...\n",
      "RMSE on the training data: 11.01\n"
     ]
    }
   ],
   "source": [
    "rmse = eval_model(lr_model, X_val, y_val, 'validation')\n",
    "print(f'RMSE on the training data: {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon-venv",
   "language": "python",
   "name": "autogluon-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
