{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42a2a44",
   "metadata": {},
   "source": [
    "# MLOps Zoomcamp - Homework #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987649be",
   "metadata": {},
   "source": [
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75466f2d",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47003cb8",
   "metadata": {},
   "source": [
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Download the data for January and February 2021.\n",
    "\n",
    "Note that you need \"For-Hire Vehicle Trip Records\", not \"High Volume For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Read the data for January. How many records are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5952943",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06120f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f379ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 22004\n",
      "-rw-r--r-- 1 user 197121 11886281 May 18 21:37 fhv_tripdata_2021-01.parquet\n",
      "-rw-r--r-- 1 user 197121 10645466 May 18 21:37 fhv_tripdata_2021-02.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0e89dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 220 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00009 2021-01-01 00:27:00 2021-01-01 00:44:00           NaN   \n",
       "1               B00009 2021-01-01 00:50:00 2021-01-01 01:07:00           NaN   \n",
       "2               B00013 2021-01-01 00:01:00 2021-01-01 01:51:00           NaN   \n",
       "3               B00037 2021-01-01 00:13:09 2021-01-01 00:21:26           NaN   \n",
       "4               B00037 2021-01-01 00:38:31 2021-01-01 00:53:44           NaN   \n",
       "\n",
       "   DOlocationID SR_Flag Affiliated_base_number  \n",
       "0           NaN    None                 B00009  \n",
       "1           NaN    None                 B00009  \n",
       "2           NaN    None                 B00013  \n",
       "3          72.0    None                 B00037  \n",
       "4          61.0    None                 B00037  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "df = pd.read_parquet('../data/fhv_tripdata_2021-01.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c45a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dispatching_base_num, pickup_datetime, dropOff_datetime, PUlocationID, DOlocationID, SR_Flag, Affiliated_base_number]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['DOlocationID'] == 110.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c639c71",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e5dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = len(df)\n",
    "print(\"Number of records:\", len_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce6079",
   "metadata": {},
   "source": [
    "## Q2. Computing duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ada43",
   "metadata": {},
   "source": [
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the average trip duration in January?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34dcce",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63528cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_duration_feature(dataset):\n",
    "    \"\"\"Create a new feature called duration\"\"\"\n",
    "    dataset['duration'] = dataset.dropOff_datetime - dataset.pickup_datetime\n",
    "    dataset.duration = dataset.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59938203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_duration_feature(df)\n",
    "avg_duration = round(df.duration.mean(), 2)\n",
    "\n",
    "print('Average trip duration in January was', avg_duration, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafed271",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2513ce3",
   "metadata": {},
   "source": [
    "Check the distribution of the duration variable. There are some outliers.\n",
    "\n",
    "Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "How many records did you drop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa18ec",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(dataset):\n",
    "    return dataset[(dataset.duration >= 1) & (dataset.duration <= 60)]\n",
    "\n",
    "df = filter_dataset(df)\n",
    "\n",
    "print(\"The number of dropped rows:\", (len_df - len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b751fcd",
   "metadata": {},
   "source": [
    "## Q3. Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99325e5f",
   "metadata": {},
   "source": [
    "The features we'll use for our model are the pickup and dropoff location IDs.\n",
    "\n",
    "But they have a lot of missing values there. Let's replace them with \"-1\".\n",
    "\n",
    "What's the fractions of missing values for the pickup location ID? I.e. fraction of \"-1\"s after you filled the NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07155110",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee1ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_values(dataset):\n",
    "    \"\"\"Replace missing values by -1\"\"\"\n",
    "    dataset['PUlocationID'] = dataset['PUlocationID'].fillna(-1)\n",
    "    dataset['DOlocationID'] = dataset['DOlocationID'].fillna(-1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = replace_missing_values(df)\n",
    "\n",
    "missing_values_fraction = round(df['PUlocationID'].value_counts()[-1] / len(df), 2)\n",
    "\n",
    "print('Fraction of missing values in the PUlocationID column is', missing_values_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b68e8",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ecd2e",
   "metadata": {},
   "source": [
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer\n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix? (The number of columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493a6bf",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_and_y(dataset):\n",
    "    \"\"\"Extract features (X) and target variable (y)\"\"\"\n",
    "    # Convert the selected columns to categories\n",
    "    categorical = ['PUlocationID', 'DOlocationID']\n",
    "    dataset[categorical] = dataset[categorical].astype(str)\n",
    "\n",
    "    # Create a list of dictionaries\n",
    "    df_dicts = dataset[categorical].to_dict(orient='records')\n",
    "\n",
    "    # Fit a dictionary vectorizer\n",
    "    dv = DictVectorizer()\n",
    "    X = dv.fit_transform(df_dicts)\n",
    "\n",
    "    # Create a target vector for model training\n",
    "    target = 'duration'\n",
    "    y = dataset[target].values\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_x_and_y(df)\n",
    "\n",
    "print(f'The matrix has {X_train.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093196e1",
   "metadata": {},
   "source": [
    "## Q5. Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf97d5e",
   "metadata": {},
   "source": [
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "* Train a plain linear regression model with default parameters\n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7bb189",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a64c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(estimator, X, y):\n",
    "    model = estimator()\n",
    "    print(f'Training a {model.__class__.__name__} model using default hyperparameters...')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def eval_model(model, X, y, data_info='train'):\n",
    "    print(f'Evaluating the {model.__class__.__name__} model on the {data_info} dataset ...')\n",
    "    \n",
    "    # Predict the values using the training data\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    rmse = mean_squared_error(y_train, y_pred, squared=False)\n",
    "    return round(rmse, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f472bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = train_model(LinearRegression, X_train, y_train)\n",
    "\n",
    "rmse = eval_model(lr_model, X_train, y_train, 'train')\n",
    "print(f'RMSE on the training data: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7401c204",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae60f7c",
   "metadata": {},
   "source": [
    "### Prepare the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fae06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Load the validation dataset\n",
    "df = pd.read_parquet('../data/fhv_tripdata_2021-02.parquet')\n",
    "\n",
    "# Feature engineering: create an new column\n",
    "# df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "# df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "df = create_duration_feature(df)\n",
    "\n",
    "# Filter out unused values\n",
    "# df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "df = filter_dataset(df)\n",
    "\n",
    "# Replace all NaN values by -1\n",
    "# df['PUlocationID'] = df['PUlocationID'].fillna(-1)\n",
    "# df['DOlocationID'] = df['DOlocationID'].fillna(-1)\n",
    "df = replace_missing_values(df)\n",
    "\n",
    "# Convert the selected columns to categories\n",
    "# categorical = ['PUlocationID', 'DOlocationID']\n",
    "# df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "# Create a list of dictionaries\n",
    "# val_dicts = df[categorical].to_dict(orient='records')\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "# dv = DictVectorizer()\n",
    "# X_val = dv.fit_transform(val_dicts)\n",
    "\n",
    "# Create a target vector for the model training\n",
    "# target = 'duration'\n",
    "# y_val = df[target].values\n",
    "\n",
    "X_val, y_val = get_x_and_y(df)\n",
    "\n",
    "print(f'The validation matrix has {X_val.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b91a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['PUlocationID'].value_counts()\n",
    "df['PUlocationID'].isnull().values.any(), df['DOlocationID'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['DOlocationID'] == '110.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d46404",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Predict the values using the validation data\n",
    "y_pred = lr_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "rmse = round(rmse, 2)\n",
    "print(f'RMSE on the validation data: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries\n",
    "\n",
    "df2 = pd.read_parquet('../data/fhv_tripdata_2021-01.parquet')\n",
    "\n",
    "df2[['PUlocationID', 'DOlocationID']] = df2[['PUlocationID', 'DOlocationID']].astype(str)\n",
    "df_dicts2 = df2[['PUlocationID', 'DOlocationID']].to_dict(orient='records')\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "dv2 = DictVectorizer()\n",
    "X2 = dv2.fit_transform(df_dicts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db015a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_parquet('../data/fhv_tripdata_2021-02.parquet')\n",
    "df3[['PUlocationID', 'DOlocationID']] = df3[['PUlocationID', 'DOlocationID']].astype(str)\n",
    "df_dicts3 = df3[['PUlocationID', 'DOlocationID']].to_dict(orient='records')\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "dv3 = DictVectorizer()\n",
    "X3 = dv3.fit_transform(df_dicts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af6085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the difference in column names\n",
    "set(dv2.feature_names_) ^ set(dv3.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the difference in column names\n",
    "set(dv3.feature_names_) ^ set(dv2.feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b66c0c",
   "metadata": {},
   "source": [
    "{'DOlocationID=110.0'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon-venv",
   "language": "python",
   "name": "autogluon-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
